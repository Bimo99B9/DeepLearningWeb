{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a PyTorch (Parte 7)\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pglez82/DeepLearningWeb/blob/master/labs/notebooks/Introducci%C3%B3n%20a%20PyTorch%20(Parte%207).ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Cargar el dataset\n",
    "dataset = load_dataset('sst')\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "print(train_dataset)\n",
    "print(val_dataset)\n",
    "print(test_dataset)\n",
    "\n",
    "print(\"Usando el dispositivo %s\" % device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesado y visualización de datos\n",
    "En este dataset la etiqueta es un número de real, que va de 0 a 1, según la opinión sea negativa (cercano a cero) o positiva (cercano a uno). Nosotros vamos a convertir este problema a un problema binario, considerando que las opiniones con más de 0.5, son positivas y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Creamos un dataset específico para nuestro problema\n",
    "class SST2Dataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sentences = sentences\n",
    "        self.encodings = tokenizer(sentences, truncation=True, padding=True)\n",
    "        self.labels = [1 if label>=0.5 else 0 for label in labels] \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Para un elemento dado devolvemos las tres cosas que nos devuelve el tokenizer: input_ids, token_type_ids y attention_masks\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['label'] = torch.tensor(self.labels[idx])\n",
    "        item['sentence'] = self.sentences[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "base_model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(base_model_name)\n",
    "train_dataset = SST2Dataset(train_dataset['sentence'],train_dataset['label'], tokenizer=tokenizer)\n",
    "val_dataset = SST2Dataset(val_dataset['sentence'],val_dataset['label'], tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver en el código anterior, hemos creado un Dataset específico para procesar los datos de nuestro problema. En el constructor tokenizamos todas las frases del dataset. El tokenizador nos devuelve tres elementos, que posteriormente devolveremos cuando se nos pida un elemento del dataset:\n",
    "- input_ids\n",
    "- token_type_ids\n",
    "- attention_masks\n",
    "Además devolvemos:\n",
    "- label: la etiqueta del ejemplo\n",
    "- sentence: la frase original (no se necesita para el entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count_0 = train_dataset.labels.count(0)\n",
    "count_1 = train_dataset.labels.count(1)\n",
    "\n",
    "# Plotting\n",
    "labels = ['Negativa', 'Positiva']\n",
    "counts = [count_0, count_1]\n",
    "\n",
    "plt.bar(labels, counts)\n",
    "plt.title('Distribución de las opiniones en el dataset')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga del modelo base y fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(base_model_name)\n",
    "\n",
    "# Crear dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Example inference\n",
    "test_text = \"This movie is great!\"\n",
    "test_encoding = tokenizer.encode_plus(test_text, truncation=True, padding=True, return_tensors='pt')\n",
    "test_input_ids = test_encoding['input_ids'].to(device)\n",
    "test_attention_mask = test_encoding['attention_mask'].to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=test_input_ids, attention_mask=test_attention_mask)\n",
    "\n",
    "predicted_probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "predicted_label = torch.argmax(predicted_probabilities, dim=1).item()\n",
    "\n",
    "sentiment = \"positive\" if predicted_label == 1 else \"negative\"\n",
    "\n",
    "print(\"Test text:\", test_text)\n",
    "print(\"Predicted sentiment:\", sentiment)\n",
    "print(\"Predicted probabilities:\", predicted_probabilities)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
