{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a PyTorch\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/pglez82/DeepLearningWeb/blob/master/labs/notebooks/Introducci%C3%B3n%20a%20PyTorch.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "PyTorch es un framework de aprendizaje profundo desarrollado por Facebook, de **código abierto** y con contribuciones de miles de usuarios. Es una alternativa a otros frameworks como TensorFlow o MXNet. El lenguaje de programación utilizado por este framework es Python (aunque muchas de sus partes están programas en otros lenguajes como C++). En este tutorial, vamos a aprender los fundamentos de PyTorch para que puedas utilizarlo en el resto de prácticas.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primeros pasos\n",
    "Lo primero consiste en ver si tenemos PyTorch instalado y conocer su versión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "si en la salida anterior ves **cpu** será que estás ejecutando una compilación de PyTorch solo con soporte para CPU y no GPU. Si por el contrario quieres ejecutar PyTorch en una máquina con GPU como Google Colab (o incluso tu propia máquina con GPU y Cuda instalado), la salida de este comando debería indicartelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un aspecto importante en los experimentos que hagamos será la reproducibilidad de resultados. Establecemos una semilla para que todos los números aleatorios generados sean los mismos ejecución tras ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8668137e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2032)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensores\n",
    "\n",
    "Los tensores son la pieza clave en cualquier framework de aprendizaje profundo. Son equivalentes a los arrays de Numpy pero tienen ciertas diferencias muy importantes:\n",
    "\n",
    "1. Los tensores **pueden moverse entre diferentes dispositivos**. Es decir, podemos tener un tensor en CPU y moverlo a la GPU y todos los cálculos realizados con este pasarán a realizarse en este dispositivo.\n",
    "2. Los tensores están preparados para diferenciar sobre ellos (calcular las derivadas parciales necesarias para aplicar descenso de gradiente). \n",
    "\n",
    "De todas maneras, una de las principales ventajas de PyTorch es que si sabemos operar con arrays de Numpy, cambiar a hacerlo con tensores será muy sencillo. Vamos a crear nuestro primer Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5766e-19, 1.0256e-08, 2.6252e-06, 3.0957e+12],\n",
      "        [6.7738e-10, 6.7140e-07, 4.2246e-05, 1.2681e+16],\n",
      "        [2.1707e-18, 7.0952e+22, 1.7748e+28, 1.8176e+31]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(3, 4)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aquí tenemos un tensor de 3x4 de números reales, inicializado alteatoriamente. Podemos mostrar su dimensión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es posible inicializar tensores con otros valores, como por ejemplo, ceros, unos o valores aleatorios entre 0 y 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0.9887, 0.5169, 0.7733, 0.7820],\n",
      "        [0.8844, 0.8440, 0.6985, 0.2108],\n",
      "        [0.1112, 0.1474, 0.8116, 0.1859]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.zeros(3,4))\n",
    "print(torch.ones(3,4))\n",
    "print(torch.rand(3,4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra manera de crear un tensor es hacerlo desde un array de numpy existente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_arr = np.array([[1, 2], [3, 4]])\n",
    "tensor = torch.from_numpy(np_arr)\n",
    "print(tensor)\n",
    "print(tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este case se pude ver que como el array era de números enteros, el tensor resultante mantiene este tipo. Siempre podemos ver el **tipo de los elementos de un tensor** con la siguiente instrucción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(tensor.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta que **el tipo es crítico** ya que nuestra red va a requerir muchísimos parámetros que al final van a ser tensores y la memoria de nuestros dispositivos es limitada. Te recomiendo el siguiente [enlace](https://pytorch.org/docs/stable/tensors.html) para conocer los diferentes tipos y saber cuando ocupa cada uno en memoria."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de crear tensores, muchas veces es interesante convertirlos de vuelta a Numpy. Podemos hacerlo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.cpu().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta que la llamada cpu() lo que hace es mover el tensor a la cpu (si no está ya). Es importante hacer esta llamada porque para pasar el tensor a numpy tiene que estar en cpu primero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mover tensores de un dispositivo a otro podemos hacerlo de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m tensor\u001b[39m.\u001b[39;49mto(device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "tensor.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obviamente para que esto funcione debemos tener PyTorch instalado con soporte para cuda. En este caso **cuda:0** indica que queremos mover el tensor a la primera GPU del sistema."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operaciones con tensores\n",
    "\n",
    "Existen multitud de operaciones que se pueden realizar con tensores. En el siguiente [enlace](https://pytorch.org/docs/stable/tensors.html#) tienes una descripción completa de todas las operaciones que se pueden realizar. Aquí vamos a describir las más básicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5617, 0.6045],\n",
      "        [0.8110, 0.5253],\n",
      "        [0.3047, 0.6035]])\n",
      "tensor([[0.6080, 0.7342],\n",
      "        [0.1738, 0.0687],\n",
      "        [0.4052, 0.7526]])\n",
      "tensor([[1.1697, 1.3387],\n",
      "        [0.9847, 0.5940],\n",
      "        [0.7099, 1.3562]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(3,2)\n",
    "t2 = torch.rand(3,2)\n",
    "suma = t1+t2\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(suma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ten en cuenta que esta operación crea un nuevo tensor en memoria. En PyTorch es posible también realizar **operaciones sobre los mismos tensores**, para no gastar espacio extra en memoria. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1697, 1.3387],\n",
       "        [0.9847, 0.5940],\n",
       "        [0.7099, 1.3562]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.add_(t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
